{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96619d0a",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28ad09",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4ee441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re # regex\n",
    "import string \n",
    "from nltk.corpus import stopwords # remove stopwords\n",
    "from nltk.tokenize import word_tokenize # tokenizing\n",
    "from nltk.stem.snowball import SnowballStemmer # stemming (improved version of PorterStemmer)\n",
    "from nltk.stem import WordNetLemmatizer # lematizing with POS tags (optional)\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054b56fc",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "437a8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"../raw_data/articles1.csv\")\n",
    "df2 = pd.read_csv(\"../raw_data/articles2.csv\")\n",
    "df3 = pd.read_csv(\"../raw_data/articles3.csv\")\n",
    "\n",
    "frames = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d405800",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat(frames) # alterar para df no final\n",
    "df = merged_df.sample(142) # remover alterar no final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354be2df",
   "metadata": {},
   "source": [
    "### Merge Headlines with  News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01e2510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"news\"] = df[\"content\"] + \" \" + df[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75d9e799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    The FBI’s Counterintelligence Division is look...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"news\"].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250cd8bc",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8dcf44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"news_lower\"] = df[\"news\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482393fb",
   "metadata": {},
   "source": [
    "### Keep Number of Decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f1155d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nrs_count'] = df['news_lower'].str.count('\\d')\n",
    "df['nrs_count'] = df['nrs_count'].fillna(0)\n",
    "df['nrs_count'] = df['nrs_count'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "255d846c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    the fbi’s counterintelligence division is look...\n",
       "19889    democratic presidential candidate former secre...\n",
       "38615      london  —   for centuries, this modest littl...\n",
       "27109    it will take a long time to analyze exactly wh...\n",
       "8917     the trump administration did not get funding f...\n",
       "                               ...                        \n",
       "25874     retired neurosurgeon ben carson, a    of dona...\n",
       "8161      donald trump and hillary clinton have   leads...\n",
       "11213    the federal emergency management agency is mak...\n",
       "9025     the media latched on to a few absurdly overblo...\n",
       "42673     (cnn) hillary clinton’s campaign raised over ...\n",
       "Name: news_lower, Length: 142, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_lower']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efb4ae",
   "metadata": {},
   "source": [
    "### Remove Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dc3db481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_nodigits'] = df['news_lower'].apply(lambda x: ''.join(word for word in x if not word.isdigit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "436798dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    the fbi’s counterintelligence division is look...\n",
       "19889    democratic presidential candidate former secre...\n",
       "38615      london  —   for centuries, this modest littl...\n",
       "27109    it will take a long time to analyze exactly wh...\n",
       "8917     the trump administration did not get funding f...\n",
       "                               ...                        \n",
       "25874     retired neurosurgeon ben carson, a    of dona...\n",
       "8161      donald trump and hillary clinton have   leads...\n",
       "11213    the federal emergency management agency is mak...\n",
       "9025     the media latched on to a few absurdly overblo...\n",
       "42673     (cnn) hillary clinton’s campaign raised over ...\n",
       "Name: news_nodigits, Length: 142, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_nodigits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c8da999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['questions'] = df['news_nodigits'].str.count('\\?')\n",
    "df['exclamations'] = df['news_nodigits'].str.count('\\!')\n",
    "df['irony'] = df['news_nodigits'].map(lambda x: len(re.findall('\\?!|\\!\\?',str(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c468f2f",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "54c3410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2024622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_string_punctuation = string.punctuation + \"—\" + '”' + \"’\" + '“' + '´' + \"`\" + \"«\" + \"»\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e500c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_nopunct'] = df['news_nodigits'].apply(lambda x: ''.join(word for word in x if word not in real_string_punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ba502cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    the fbis counterintelligence division is looki...\n",
       "19889    democratic presidential candidate former secre...\n",
       "38615      london     for centuries this modest little ...\n",
       "27109    it will take a long time to analyze exactly wh...\n",
       "8917     the trump administration did not get funding f...\n",
       "                               ...                        \n",
       "25874     retired neurosurgeon ben carson a    of donal...\n",
       "8161      donald trump and hillary clinton have   leads...\n",
       "11213    the federal emergency management agency is mak...\n",
       "9025     the media latched on to a few absurdly overblo...\n",
       "42673     cnn hillary clintons campaign raised over  mi...\n",
       "Name: news_nopunct, Length: 142, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_nopunct']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07719def",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d749321",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa4c6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_tokens'] = df['news_nopunct'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dbe3e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    [the, fbis, counterintelligence, division, is,...\n",
       "19889    [democratic, presidential, candidate, former, ...\n",
       "38615    [london, for, centuries, this, modest, little,...\n",
       "27109    [it, will, take, a, long, time, to, analyze, e...\n",
       "8917     [the, trump, administration, did, not, get, fu...\n",
       "                               ...                        \n",
       "25874    [retired, neurosurgeon, ben, carson, a, of, do...\n",
       "8161     [donald, trump, and, hillary, clinton, have, l...\n",
       "11213    [the, federal, emergency, management, agency, ...\n",
       "9025     [the, media, latched, on, to, a, few, absurdly...\n",
       "42673    [cnn, hillary, clintons, campaign, raised, ove...\n",
       "Name: news_tokens, Length: 142, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1d27c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "082da797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_no_stop_words'] = df['news_tokens']\\\n",
    "                            .apply(lambda x: [word for word in x if not word in stop_words])\n",
    "# df['news_no_stop_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0799e",
   "metadata": {},
   "source": [
    "### Stemming (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "332c130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    [fbis, counterintellig, divis, look, role, new...\n",
       "19889    [democrat, presidenti, candid, former, secreta...\n",
       "38615    [london, centuri, modest, littl, island, north...\n",
       "27109    [take, long, time, analyz, exact, happen, extr...\n",
       "8917     [trump, administr, get, fund, border, wall, co...\n",
       "                               ...                        \n",
       "25874    [retir, neurosurgeon, ben, carson, donald, tru...\n",
       "8161     [donald, trump, hillari, clinton, lead, race, ...\n",
       "11213    [feder, emerg, manag, agenc, make, sweep, refo...\n",
       "9025     [media, latch, absurd, overblown, stori, keep,...\n",
       "42673    [cnn, hillari, clinton, campaign, rais, millio...\n",
       "Name: news_stemmed, Length: 142, dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "df['news_stemmed'] = df['news_no_stop_words']\\\n",
    "                            .apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "df['news_stemmed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8369ca",
   "metadata": {},
   "source": [
    "### Lematizing with POS tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70e9a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# 1. Init Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 2. Lemmatize a Sentence with the appropriate POS tag\n",
    "df['news_lemmatized'] = df['news_no_stop_words']\\\n",
    "                            .map(lambda x: [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e8c74ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    [fbi, counterintelligence, division, look, rol...\n",
       "19889    [democratic, presidential, candidate, former, ...\n",
       "38615    [london, century, modest, little, island, nort...\n",
       "27109    [take, long, time, analyze, exactly, happen, e...\n",
       "8917     [trump, administration, get, funding, border, ...\n",
       "                               ...                        \n",
       "25874    [retire, neurosurgeon, ben, carson, donald, tr...\n",
       "8161     [donald, trump, hillary, clinton, lead, race, ...\n",
       "11213    [federal, emergency, management, agency, make,...\n",
       "9025     [medium, latch, absurdly, overblown, story, ke...\n",
       "42673    [cnn, hillary, clinton, campaign, raise, milli...\n",
       "Name: news_lemmatized, Length: 142, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_lemmatized']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac1516f",
   "metadata": {},
   "source": [
    "### Vocab richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "439e2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_lemmatized_str'] = df['news_lemmatized'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e533039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cce3e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12596    0.747748\n",
       "19889    0.591054\n",
       "38615    0.581028\n",
       "27109    0.696379\n",
       "8917     0.829268\n",
       "           ...   \n",
       "25874    0.632124\n",
       "8161     0.432056\n",
       "11213    0.574468\n",
       "9025     0.646840\n",
       "42673    0.590909\n",
       "Name: vocab richness, Length: 142, dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "df['vocab richness'] = df['news_lemmatized_str'].apply(lambda x: vocab_richness(x))\n",
    "\n",
    "df['vocab richness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed688169",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2a5e3",
   "metadata": {},
   "source": [
    "#### Strings for Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58f01c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_lemmatized'] = df['news_lemmatized'].map(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e253",
   "metadata": {},
   "source": [
    "#### Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8609468",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range = (1,1), max_df = 0.8, min_df = 0.2, max_features=None)\n",
    "X = tf_idf_vectorizer.fit_transform(df['news_lemmatized'])\n",
    "X = X.toarray()\n",
    "#tf_idf_vectorizer.get_feature_names()\n",
    "#pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2627d624",
   "metadata": {},
   "source": [
    "### Testing main preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "19f7b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coiso\n"
     ]
    }
   ],
   "source": [
    "arg1 = [\"coluna\", \"csv\", \"etc\"]\n",
    "arg2 = {\"coiso\":True, \"teste\":False}\n",
    "\n",
    "def test(*args, **kwargs):\n",
    "    if args[0] == \"coluna\":\n",
    "        print(\"coiso\")\n",
    "test(*arg1, **arg2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caa6b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(\"../big_picture/data/data_30k_all_true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "916c1adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'invalid file advanced hike two option really stood first right across desert botanical garden one little adventure lot grapefruit valley sun'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"news_all_data\"].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef23ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
