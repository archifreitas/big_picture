{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06852b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362adb93",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21866ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 18047 to 31129\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1000 non-null   int64  \n",
      " 1   id           1000 non-null   int64  \n",
      " 2   title        1000 non-null   object \n",
      " 3   publication  1000 non-null   object \n",
      " 4   author       885 non-null    object \n",
      " 5   date         1000 non-null   object \n",
      " 6   year         1000 non-null   float64\n",
      " 7   month        1000 non-null   float64\n",
      " 8   url          0 non-null      float64\n",
      " 9   content      1000 non-null   object \n",
      "dtypes: float64(3), int64(2), object(5)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"../raw_data/articles1.csv\").sample(frac = 0.02)\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f274adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18047    During the weeks before the final day of the c...\n",
       "30432    Though Marco Rubio has consistently opposed th...\n",
       "31380    Sunday in an appearance on Fox News Channel’s ...\n",
       "4170     HOBOKEN, N. J.  —   Federal investigators have...\n",
       "42689    Atlanta  (CNN) A   video from ISIS shows milit...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_content = raw_data.content\n",
    "raw_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34be08",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "349737f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x29720 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 284689 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = raw_content\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b287a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "tf_idf_model = KMeans(n_clusters=20).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bfe053b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('tesla', 0.3961301801853234), ('the', 0.1706194914544641), ('musk', 0.16157716531489766), ('lithium', 0.12966018712048247), ('vehicles', 0.12006567328859741), ('cars', 0.10888838236925824), ('car', 0.10525605936718614), ('to', 0.09638655704411865), ('and', 0.09121401543684719), ('of', 0.09036275869688043)]\n",
      "Topic 1:\n",
      "[('sanders', 0.2715483345973047), ('the', 0.18832245572405673), ('bernie', 0.10954821251486507), ('clinton', 0.08970331219462485), ('of', 0.08892221904962866), ('to', 0.0870939499711534), ('in', 0.07762883070834521), ('delegates', 0.07760940283506548), ('democratic', 0.06426641275042232), ('and', 0.06126980259124733)]\n",
      "Topic 2:\n",
      "[('the', 0.2756052861946203), ('israeli', 0.2563009065937392), ('palestinian', 0.1881284861412586), ('israel', 0.14087949571239158), ('to', 0.09820778585697122), ('palestinians', 0.09544732914420685), ('dermer', 0.08363033670263317), ('of', 0.0819145526502959), ('and', 0.0685752593324952), ('in', 0.05876164299907806)]\n",
      "Topic 3:\n",
      "[('the', 0.24158909794098643), ('to', 0.13630912862138267), ('of', 0.09711258763752655), ('in', 0.08697643327712165), ('and', 0.08658988223680698), ('ryan', 0.07908973776728863), ('that', 0.06516939268935988), ('cruz', 0.05779309251966569), ('rubio', 0.057464644870080545), ('trump', 0.05643239387346087)]\n",
      "Topic 4:\n",
      "[('the', 0.17720030804187342), ('to', 0.08561662429680926), ('of', 0.07711232793624215), ('and', 0.07688110240443286), ('in', 0.06640938685614191), ('that', 0.03816796984750448), ('on', 0.03577862464734645), ('for', 0.035211376593277034), ('was', 0.032038772100473074), ('is', 0.02945498783502531)]\n",
      "Topic 5:\n",
      "[('the', 0.275835882540134), ('mr', 0.25289616462568454), ('to', 0.13572408152646762), ('of', 0.12932060444025809), ('and', 0.12047595318435446), ('in', 0.10880144503024036), ('trump', 0.08027101900508699), ('that', 0.0738165396654754), ('he', 0.07194154979203693), ('his', 0.06189434986817054)]\n",
      "Topic 6:\n",
      "[('the', 0.26684493907135276), ('eu', 0.20680173653261358), ('to', 0.13648616805051886), ('of', 0.12510453987188683), ('european', 0.11359018283601369), ('brexit', 0.11041027814963263), ('britain', 0.09640089620533203), ('migrants', 0.08665961065262695), ('in', 0.08650512321756282), ('farage', 0.07498402001525434)]\n",
      "Topic 7:\n",
      "[('gun', 0.16321300636537522), ('the', 0.15811518609452124), ('awrhawkins', 0.12096512036827897), ('and', 0.09219631009322737), ('to', 0.09038050821978603), ('checks', 0.07563721597686943), ('awr', 0.0722324814837533), ('background', 0.07220855658702996), ('hawkins', 0.07154167234224923), ('breitbart', 0.07042698681648785)]\n",
      "Topic 8:\n",
      "[('korea', 0.34827225314687416), ('north', 0.2853316181760883), ('the', 0.21402917286392023), ('korean', 0.13538086929642573), ('to', 0.1263027421668158), ('kim', 0.10222955135519787), ('tillerson', 0.09995131169013702), ('of', 0.09810925310172638), ('nuclear', 0.09267791736458074), ('china', 0.09022836359625977)]\n",
      "Topic 9:\n",
      "[('the', 0.16691127879935871), ('clinton', 0.1444994141480804), ('trump', 0.12513331953236007), ('to', 0.09168909211651169), ('of', 0.08224244382422294), ('and', 0.06916706712529226), ('in', 0.06254054803314942), ('that', 0.05982237498436306), ('hillary', 0.055863288726565034), ('he', 0.046551279793715476)]\n",
      "Topic 10:\n",
      "[('the', 0.3187072710572141), ('of', 0.13949794092372006), ('to', 0.12879685675053865), ('and', 0.11691904368988228), ('in', 0.10469151902639555), ('that', 0.06209545563121293), ('for', 0.045597400763643), ('is', 0.04444448310480887), ('on', 0.0442335299806181), ('was', 0.04180633626388596)]\n",
      "Topic 11:\n",
      "[('the', 0.20579480380394238), ('to', 0.14537514632489515), ('and', 0.11684437266635464), ('you', 0.11679269810245334), ('of', 0.09483763723455149), ('that', 0.09466570947657534), ('in', 0.07967338808163554), ('it', 0.07160198508749607), ('is', 0.06053223317123868), ('we', 0.0542346846783477)]\n",
      "Topic 12:\n",
      "[('parenthood', 0.37826156890708545), ('planned', 0.28626599192455193), ('the', 0.20654983210362488), ('abortion', 0.17586039438242856), ('to', 0.12999390292875643), ('and', 0.09226081727223852), ('of', 0.09219442845350541), ('daleiden', 0.08289267215526239), ('in', 0.07372800651007262), ('that', 0.07191450075329404)]\n",
      "Topic 13:\n",
      "[('the', 0.2753131772379701), ('trump', 0.1385212137105607), ('to', 0.13714842701253385), ('of', 0.1137463002337516), ('and', 0.09335690674407986), ('that', 0.09254124685522284), ('in', 0.0825305278838939), ('he', 0.08027179138216341), ('comey', 0.07246357867620386), ('his', 0.0609116441561152)]\n",
      "Topic 14:\n",
      "[('migrants', 0.2641847094060213), ('the', 0.24939196000212022), ('to', 0.112682204961646), ('in', 0.09941368511450124), ('of', 0.08623437314585458), ('asylum', 0.07387719950468932), ('cent', 0.07007273293155938), ('are', 0.06156521278839823), ('uk', 0.06131144924348701), ('jungle', 0.05622423813077603)]\n",
      "Topic 15:\n",
      "[('the', 0.2028145374514086), ('city', 0.11672722854791584), ('of', 0.09019528799793991), ('to', 0.08987402575493521), ('in', 0.08453987583234417), ('lee', 0.07373309974960689), ('and', 0.06964011044159392), ('police', 0.06618976638424054), ('uber', 0.059671708191948294), ('confederate', 0.05839526887249216)]\n",
      "Topic 16:\n",
      "[('the', 0.16452947729013523), ('jones', 0.162843779902346), ('twitter', 0.13153546727231938), ('leslie', 0.107314284456304), ('county', 0.10035845013546436), ('to', 0.08753406462692398), ('milo', 0.08717484165083099), ('permits', 0.08625858359103444), ('batchelor', 0.08095269642494878), ('hatetwitter', 0.0762403114746102)]\n",
      "Topic 17:\n",
      "[('the', 0.23183099937388418), ('students', 0.1327490040293077), ('to', 0.11809975749252034), ('of', 0.11445226074348418), ('and', 0.1065987153028119), ('university', 0.09009336292975782), ('in', 0.08317159531924274), ('college', 0.07047728042678661), ('student', 0.06972305375290265), ('that', 0.06525154553923784)]\n",
      "Topic 18:\n",
      "[('her', 0.21323339252772788), ('she', 0.14569646949939982), ('the', 0.11168368015495324), ('to', 0.09970217860236104), ('daughter', 0.09168538374363494), ('baloch', 0.09039267777518745), ('parham', 0.08218568675712486), ('was', 0.07992319216898044), ('knox', 0.07756744388431817), ('shahid', 0.07638009719376428)]\n",
      "Topic 19:\n",
      "[('milo', 0.357609156967052), ('the', 0.16522194478911637), ('scahill', 0.10863187395018477), ('nike', 0.106215292474577), ('yiannopoulos', 0.10547499032026969), ('doyle', 0.088513497270272), ('of', 0.08779655514828265), ('and', 0.08196965172270235), ('maher', 0.07893611029599107), ('article', 0.07541855487176509)]\n"
     ]
    }
   ],
   "source": [
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(tf_idf_model.cluster_centers_, tf_idf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cece82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=20).fit(X)\n",
    "\n",
    "print_topics(lda_model.components_, tf_idf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8eb7f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0034004 , 0.0034004 , 0.0034004 , 0.0034004 , 0.5353657 ,\n",
       "        0.0034004 , 0.0034004 , 0.0034004 , 0.0034004 , 0.0034004 ,\n",
       "        0.0034004 , 0.20329059, 0.0034004 , 0.0034004 , 0.07443649,\n",
       "        0.0034004 , 0.13250081, 0.0034004 , 0.0034004 , 0.0034004 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.transform(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d03a96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "text_list = [text_to_word_sequence(sentence) for sentence in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94ea3b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2100628 ,  0.1537489 ,  0.87903917, -0.5523931 , -0.07621907,\n",
       "       -0.07617197,  0.4168468 ,  0.9264497 , -0.6768583 , -0.920836  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(sentences=text_list, vector_size=10)\n",
    "\n",
    "word2vec.wv[\"tesla\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e8d67a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence.split(\" \"))\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_embed = embedding(word2vec, texts)\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n",
    "shape_output = max([array.size for array in X_embed])\n",
    "#X = pad_sequences(X_embed, dtype='float32', padding='post', maxlen=shape_output).reshape(1000,shape_output*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd853fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c11e7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "X = csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "842f8a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clinton', 0.8887618780136108),\n",
       " ('trump’s', 0.8878629207611084),\n",
       " ('election', 0.8647207617759705),\n",
       " ('cruz', 0.8619100451469421),\n",
       " ('obama', 0.8521750569343567),\n",
       " ('ryan', 0.8442927598953247),\n",
       " ('candidate', 0.8231729865074158),\n",
       " ('unimatrixzeroone', 0.8141018152236938),\n",
       " ('’a', 0.8074794411659241),\n",
       " ('marc', 0.807149350643158)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3b24b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-725cbf11d905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Topic %d:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     print([word2vec.wv.most_similar(positive=topic[i], topn=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m                     for i in topic.argsort()[:-10 - 1:-1]])\n",
      "\u001b[0;32m<ipython-input-120-725cbf11d905>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Topic %d:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     print([word2vec.wv.most_similar(positive=topic[i], topn=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m                     for i in topic.argsort()[:-10 - 1:-1]])\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;31m# add weights for each key, if not already present; default to 1.0 for positive and -1.0 for negative keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         positive = [\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKEY_TYPES\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "tf_idf_model = KMeans(n_clusters=20).fit(X)\n",
    "\n",
    "for idx, topic in enumerate(tf_idf_model.cluster_centers_):\n",
    "    print(\"Topic %d:\" % (idx))\n",
    "    print([word2vec.wv.most_similar(positive=[topic[i]], topn=1)\n",
    "                    for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "83e83c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03203c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
